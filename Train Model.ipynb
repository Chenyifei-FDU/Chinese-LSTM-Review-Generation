{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "import load\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "from load import sentence2vector\n",
    "from load import vector2sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs, output_dim):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "\n",
    "    a = TimeDistributed(Dense(1, activation='tanh'))(inputs)\n",
    "    a = Flatten()(a)\n",
    "    a = Activation('softmax')(a)\n",
    "    a = RepeatVector(output_dim)(a)\n",
    "    a = Permute([2, 1])(a)\n",
    "\n",
    "    sent_representation = merge([inputs, a], mode='mul')\n",
    "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "\n",
    "    return sent_representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=0.5):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(value_vector, max_type = 5,one_index=False):\n",
    "    one_hot_matrix = np.zeros([value_vector.shape[0],max_type],dtype=np.uint8)\n",
    "    for i,score in enumerate(value_vector):\n",
    "        one_hot_matrix[i,score-int(one_index)] = 1\n",
    "    return one_hot_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iteration=60\n",
    "preprocessor = load.Preprocessor(r'./Data')\n",
    "preprocessor.load_char_embedding(filename='clean_embedding.txt')\n",
    "print(len(preprocessor.char2indice))\n",
    "print((preprocessor.char_embedding_matrix.shape))\n",
    "X,Score, Y = load.build_X_Y_score('sample.json',preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19092\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 32\n",
    "LSTM_UNITS=256\n",
    "preprocessor = load.Preprocessor(r'./Data')\n",
    "# preprocessor.load_char_embedding(filename='clean_embedding.txt')\n",
    "preprocessor.load_word_indice('word_count_10.tsv')\n",
    "print(len(preprocessor.word2indice))\n",
    "# print(len(preprocessor.char_embedding_matrix.shape))\n",
    "# model_build\n",
    "output_shape=len(preprocessor.word2indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "my_embedding_layer = Embedding(preprocessor.n_word,output_dim=128,\n",
    "                               input_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "a=Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x1 = Masking(mask_value=0, input_shape=(MAX_SEQUENCE_LENGTH,))(a)\n",
    "x1 = my_embedding_layer(x1)\n",
    "x1 = LSTM(units=LSTM_UNITS, activation='tanh',return_sequences=True)(x1)\n",
    "print(x1.shape)\n",
    "# x1 = LSTM(units=512, activation='tanh')(x1)\n",
    "x1 = attention_3d_block(x1,LSTM_UNITS)\n",
    "print(x1.shape)\n",
    "x = Dense(512, activation='relu')(x1)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "b = Input(shape=(5,))\n",
    "x = concatenate([x, b])\n",
    "x = Dense(output_shape, activation='softmax')(x)\n",
    "\n",
    "# x = Dropout(0.3)(x)\n",
    "model = Model(inputs=[a, b], outputs=x)\n",
    "# optimizer = RMSprop(0.003)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "# earlyStop=keras.callbacks.EarlyStopping(monitor='val_acc',mode='max',patience=20)\n",
    "# saveBestModel=keras.callbacks.ModelCheckpoint(filepath='lstm_attention.{epoch:02d-{val_acc:.2f}}.hdf5',monitor='val_acc',save_best_only=True,mode='max')\n",
    "iteration=20\n",
    "for _ in range(iteration):\n",
    "    \n",
    "    \n",
    "    fold=20\n",
    "    data_generator = load.build_X_Y_score('review_word.tsv',preprocessor=preprocessor,fold=fold,duplicate=10 ,max_len=MAX_SEQUENCE_LENGTH,begin=-32,stop=-30)\n",
    "    for i in range(fold):\n",
    "        print('\\n','iteration,fold:',_+1,i)\n",
    "        X,Score,Y = next(data_generator)\n",
    "        #print(X.shape,Score.shape,Y.shape)\n",
    "        Y=load.one_hot_encoder(Y,len(preprocessor.word2indice),one_index=False)\n",
    "        model.fit(x=[X,Score],y=Y,batch_size=64,epochs=1,validation_split=0.1,shuffle=True,)\n",
    "        \n",
    "    model.save('./models/lstm_attention_iteration%d_units_%d_val-acc_%.3f.h5'%(_+1,LSTM_UNITS,model.history.history['val_acc'][0]))\n",
    "# model.save('LSTM_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:1253: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model('./models/lstm_attention_iteration8_units_256_val-acc_0.314.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- score: 5\n",
      "a.shape (1, 32)\n",
      "7102\n",
      "a.shape (1, 32)\n",
      "12744\n",
      "a.shape (1, 32)\n",
      "9694\n",
      "a.shape (1, 32)\n",
      "7067\n",
      "a.shape (1, 32)\n",
      "3\n",
      "很好吃，尤其是招牌鸡…吃饭之间还有 学生用餐的。\n"
     ]
    }
   ],
   "source": [
    "score=5\n",
    "print()\n",
    "print('----- score:', score)\n",
    "\n",
    "# sentence_indice=list(np.ones([MAX_SEQUENCE_LENGTH],dtype=np.uint32)*0)\n",
    "# sentence_indice[-1]=2\n",
    "seed='很 好吃 ， 尤其是 招牌 鸡 … 吃饭 之间 还 有'\n",
    "vector=seed.split(' ')\n",
    "sentence_vector =  ['padding']*(MAX_SEQUENCE_LENGTH-len(vector))+vector\n",
    "sentence_vector = sentence2vector(sentence_vector,preprocessor)\n",
    "# generated = ''.join(vector2sentence(sentence_vector,preprocessor))\n",
    "#2代表的是<sor>的indice\n",
    "score_one_hot=np.zeros([1,5])\n",
    "score_one_hot[0,score-1]=1\n",
    "b=score_one_hot\n",
    "generated_vector=[]\n",
    "while (True):\n",
    "    \n",
    "    a=np.array([sentence_vector])\n",
    "    print(\"a.shape\",a.shape)\n",
    "    softmax_vector=model.predict([a,b])[0]\n",
    "    \n",
    "    next_index = sample(softmax_vector, temperature=0.7)\n",
    "    print(next_index)\n",
    "    if next_index == 3:\n",
    "        break\n",
    "    sentence_vector.pop(0)\n",
    "    sentence_vector.append(next_index)\n",
    "    generated_vector.append(next_index)\n",
    "    \n",
    "# print(sentence_vector)\n",
    "generated=''.join(vector2sentence(generated_vector,preprocessor))\n",
    "print(''.join(seed.split(' ')),generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
